{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fa52b3b",
   "metadata": {},
   "source": [
    "### Matrix formulation using pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a0b6e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bce8014f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3, 5],\n",
       "        [1, 2, 9]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[2, 3, 5],[1, 2, 9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54f72c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3335, 0.3502],\n",
       "        [0.7910, 0.1650]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e962f317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand((3, 5))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7632a096",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1490, 0.3160, 0.6597, 0.5707, 0.4763],\n",
      "        [0.9019, 0.6169, 0.3325, 0.6233, 0.0053],\n",
      "        [0.5741, 0.1126, 0.9718, 0.4415, 0.1306]])\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1739ad",
   "metadata": {},
   "source": [
    "### Matrix formation using numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd7b75ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3, 5],\n",
       "       [1, 2, 9]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.array([[2, 3, 5], [1, 2, 9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7314503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.88709775, 0.07082287],\n",
       "       [0.1096779 , 0.46369997]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d5e6be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.8493118  -0.83921889 -0.68527776  0.40523211  0.01020729]\n",
      " [ 0.3509976   1.14614562 -0.86163311  0.09308297  0.82061612]\n",
      " [-0.38461001 -0.58777828  1.77984613  0.00860337 -0.59306172]]\n"
     ]
    }
   ],
   "source": [
    "a = np.random.randn(3, 5)\n",
    "a.shape\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525dbb91",
   "metadata": {},
   "source": [
    "### Construct a randomly initialized matrix and operation using Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7928ce24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8409, 0.7544],\n",
      "        [0.4864, 0.6440]])\n",
      "tensor([[0.4460, 0.1140],\n",
      "        [0.3941, 0.2157]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand((2, 2))\n",
    "b = torch.rand((2, 2))\n",
    "\n",
    "print(a)\n",
    "\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37ff7a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6724, 0.2585],\n",
       "        [0.4708, 0.1943]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ced823b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3750, 0.0860],\n",
       "        [0.1917, 0.1389]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e003776d",
   "metadata": {},
   "source": [
    "### Construct a randomly initialized matrix and operation using NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05ab1dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(2, 2)\n",
    "b = np.random.rand(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a93b3b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7653224 , 0.48476201],\n",
       "       [0.23174327, 0.24750403]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(a, b)\n",
    "\n",
    "# normal matrix multiplication\n",
    "\n",
    "# Where the condition of number of columns of first array should be equal to number of rows of second array is checked\n",
    "\n",
    "# than only numpy.dot() function take place else it shows an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6775fb0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16953529, 0.54954758],\n",
       "       [0.23071601, 0.03469407]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply(a, b)\n",
    "\n",
    "# '*' operation carries out element-wise multiplication on array elements.\n",
    "\n",
    "# The element at a[i][j] is multiplied with b[i][j]. This happens for all elements of array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef54560",
   "metadata": {},
   "source": [
    "### Construct a 5x3 matrix, uninitialized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53b40f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0102e-38, 1.0286e-38, 1.0194e-38],\n",
      "        [9.6429e-39, 9.2755e-39, 9.1837e-39],\n",
      "        [9.3674e-39, 1.0745e-38, 1.0653e-38],\n",
      "        [9.5510e-39, 1.0561e-38, 1.0194e-38],\n",
      "        [1.1112e-38, 1.0561e-38, 9.9184e-39]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdc5def",
   "metadata": {},
   "source": [
    "### Construct a matrix filled zeros and of dtype long:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f146a5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_torch = torch.zeros(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aba98b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_numpy = np.zeros((2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c63657d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "776537b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_torch = torch.ones(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11bb2611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "b_numpy = np.zeros((2, 2))\n",
    "\n",
    "print(a_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a12bdbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3, dtype = torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71711c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "b_torch = torch.ones(2, 2)\n",
    "\n",
    "print(b_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "518a0abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1.]\n",
      " [1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "b_numpy = np.ones((2, 2))\n",
    "\n",
    "print(b_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3586beb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "c_numpy = np.identity(2)\n",
    "\n",
    "# Python NumPy identity() is an inbuilt NumPy function that is used for returning a matrix i.e.,\n",
    "\n",
    "# a 2D array having 1's at its main diagonal and 0's elsewhere\n",
    "\n",
    "print(c_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2cc29f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.],\n",
      "        [0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "c_torch = torch.eye(2)\n",
    "\n",
    "print(c_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27ecd6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.],\n",
      "        [0., 1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "d_torch = torch.from_numpy(c_numpy)\n",
    "\n",
    "print(d_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3bb85700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "d = c_torch.numpy()\n",
    "\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ec74dd",
   "metadata": {},
   "source": [
    "### Construct a tensor directly from data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e7575ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87343fb2",
   "metadata": {},
   "source": [
    "### Create a tensor based on an existing tensor. These methods will reuse properties of the input tensor, e.g. dtype, unless new values are provided by user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f87fbd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[-1.3959, -0.3461,  0.1696],\n",
      "        [-0.3948, -0.7275,  1.3900],\n",
      "        [ 1.1550, -0.8947,  0.6415],\n",
      "        [-0.1248, -0.9158,  0.8163],\n",
      "        [ 0.2196, -0.0094,  0.3906]])\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(5, 3, dtype=torch.double) #new_* methods take in sizes\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x, dtype=torch.float) # override dtype!\n",
    "print(x) # result has the same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "326cebc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f3c1bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3655, 0.3404, 0.7335],\n",
      "        [0.5155, 0.9287, 0.8116],\n",
      "        [0.1133, 0.8328, 0.2075],\n",
      "        [0.3790, 0.1071, 0.9723],\n",
      "        [0.3013, 0.7502, 0.8146]])\n",
      "tensor([[-1.3959, -0.3461,  0.1696],\n",
      "        [-0.3948, -0.7275,  1.3900],\n",
      "        [ 1.1550, -0.8947,  0.6415],\n",
      "        [-0.1248, -0.9158,  0.8163],\n",
      "        [ 0.2196, -0.0094,  0.3906]])\n",
      "tensor([[-1.0304, -0.0057,  0.9031],\n",
      "        [ 0.1207,  0.2012,  2.2016],\n",
      "        [ 1.2683, -0.0620,  0.8490],\n",
      "        [ 0.2542, -0.8087,  1.7886],\n",
      "        [ 0.5210,  0.7408,  1.2052]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5, 3)\n",
    "print(y)\n",
    "print(x)\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3312835b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0304, -0.0057,  0.9031],\n",
      "        [ 0.1207,  0.2012,  2.2016],\n",
      "        [ 1.2683, -0.0620,  0.8490],\n",
      "        [ 0.2542, -0.8087,  1.7886],\n",
      "        [ 0.5210,  0.7408,  1.2052]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8b8de0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0304, -0.0057,  0.9031],\n",
      "        [ 0.1207,  0.2012,  2.2016],\n",
      "        [ 1.2683, -0.0620,  0.8490],\n",
      "        [ 0.2542, -0.8087,  1.7886],\n",
      "        [ 0.5210,  0.7408,  1.2052]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(5, 3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a54ff63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0304, -0.0057,  0.9031],\n",
      "        [ 0.1207,  0.2012,  2.2016],\n",
      "        [ 1.2683, -0.0620,  0.8490],\n",
      "        [ 0.2542, -0.8087,  1.7886],\n",
      "        [ 0.5210,  0.7408,  1.2052]])\n"
     ]
    }
   ],
   "source": [
    "# adds x to y\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "48b51ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.3959, -0.3461,  0.1696],\n",
      "        [-0.3948, -0.7275,  1.3900],\n",
      "        [ 1.1550, -0.8947,  0.6415],\n",
      "        [-0.1248, -0.9158,  0.8163],\n",
      "        [ 0.2196, -0.0094,  0.3906]])\n",
      "tensor([-0.3461, -0.7275, -0.8947, -0.9158, -0.0094])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "\n",
    "print(x[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7793982b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "\n",
    "y = x.view(16)\n",
    "\n",
    "z = x.view(-1, 8) # the size -1 is inferred from other dimensions\n",
    "\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97286233",
   "metadata": {},
   "source": [
    "### numpy.random.randn generates samples from the normal distribution (mean 0 and variance 1, while numpy.random.rand from a uniform distribution(in the range[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8aa74ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you have one element tensor, use .item() to get the values as a Python number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a3cd4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8300])\n",
      "0.8300303816795349\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4641ea2",
   "metadata": {},
   "source": [
    "## NumPy Bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bf6d9dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "67c4366a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee9edc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0e32d051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5c456f",
   "metadata": {},
   "source": [
    "## CUDA Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e3fee28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuba\")\n",
    "    y = torch.ones_like(x, device=device)\n",
    "    x = x.to(device)\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5c3baf",
   "metadata": {},
   "source": [
    "### Forward Propogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2c698956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.]) tensor([-4.]) tensor([8.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([2])\n",
    "b = torch.Tensor([-4])\n",
    "c = torch.Tensor([-2])\n",
    "d = torch.Tensor([2])\n",
    "\n",
    "e = a + b\n",
    "f = c * d\n",
    "\n",
    "g = e * f\n",
    "print(e, f, g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f22a4c",
   "metadata": {},
   "source": [
    "### Backward Propogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dc5b4fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of z is: tensor(2.)\n",
      "Gradient of y is: tensor(-2.)\n",
      "Gradient of x is: tensor(-2.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor(-3., requires_grad=True)\n",
    "y = torch.tensor(5., requires_grad=True)\n",
    "z = torch.tensor(-2., requires_grad=True)\n",
    "\n",
    "q = x + y\n",
    "f = q * z\n",
    "\n",
    "f.backward()\n",
    "\n",
    "print(\"Gradient of z is: \" + str(z.grad))\n",
    "print(\"Gradient of y is: \" + str(y.grad))\n",
    "print(\"Gradient of x is: \" + str(x.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525fe089",
   "metadata": {},
   "source": [
    "#### initialize tensors x, y and z to values 4, -3 and 5. Put the sum of tensors x and y in q, put the product of q and z in f. Calculate the derivatives of the computational graph.Print the gradients of the x, y and z tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c4af5a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of x is: tensor(5.)\n",
      "Gradient of y is: tensor(5.)\n",
      "Gradient of z is: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# Initialize x, y and z to values 4, -3 and 5\n",
    "x = torch.tensor(4., requires_grad=True)\n",
    "y = torch.tensor(-3., requires_grad=True)\n",
    "z = torch.tensor(5., requires_grad=True)\n",
    "\n",
    "# Set q to sum of x and y, set f to product of q with z\n",
    "q = x + y\n",
    "f = q * z\n",
    "\n",
    "# Compute the derivatives\n",
    "f.backward()\n",
    "\n",
    "print(\"Gradient of x is: \" + str(x.grad))\n",
    "print(\"Gradient of y is: \" + str(y.grad))\n",
    "print(\"Gradient of z is: \" + str(z.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4e8700",
   "metadata": {},
   "source": [
    "#### Initialize a random tensors x, y and z, each having shape(1000, 1000) multiply x with y, putting the result in tensor q. Do an elementwise multiplication of tensor q, putting the results in f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bb6d4115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(124.9837, grad_fn=<MeanBackward0>)\n",
      "Gradient of x is: tensor([[0.0003, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0003, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0003, 0.0002, 0.0002,  ..., 0.0002, 0.0003, 0.0002],\n",
      "        ...,\n",
      "        [0.0003, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0003, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0003, 0.0002, 0.0002]])\n",
      "Gradient of y is: tensor([[0.0003, 0.0003, 0.0003,  ..., 0.0002, 0.0003, 0.0003],\n",
      "        [0.0002, 0.0003, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0003, 0.0003, 0.0003,  ..., 0.0002, 0.0003, 0.0002],\n",
      "        ...,\n",
      "        [0.0003, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0003, 0.0003, 0.0003,  ..., 0.0002, 0.0003, 0.0002],\n",
      "        [0.0002, 0.0003, 0.0002,  ..., 0.0002, 0.0002, 0.0002]])\n",
      "Gradient of z is: tensor([[0.0002, 0.0002, 0.0002,  ..., 0.0003, 0.0003, 0.0003],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0003, 0.0002, 0.0003],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0003, 0.0003, 0.0003],\n",
      "        ...,\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0003, 0.0002, 0.0003],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0003, 0.0002, 0.0003],\n",
      "        [0.0002, 0.0002, 0.0003,  ..., 0.0003, 0.0002, 0.0003]])\n"
     ]
    }
   ],
   "source": [
    "# Initialize x, y and z to values 4, -3 and 5\n",
    "x = torch.rand(1000, 1000, requires_grad=True)\n",
    "y = torch.rand(1000, 1000, requires_grad=True)\n",
    "z = torch.rand(1000, 1000, requires_grad=True)\n",
    "\n",
    "# Multiply x with y\n",
    "q = torch.matmul(x, y)\n",
    "\n",
    "# Multiply elementwise z with q\n",
    "f = z * q\n",
    "\n",
    "mean_f = torch.mean(f)\n",
    "print(mean_f)\n",
    "\n",
    "mean_f.backward()\n",
    "\n",
    "# Print the gradients\n",
    "print(\"Gradient of x is: \" + str(x.grad))\n",
    "print(\"Gradient of y is: \" + str(y.grad))\n",
    "print(\"Gradient of z is: \" + str(z.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd41986f",
   "metadata": {},
   "source": [
    "### Fully connected neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "961ccd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.7602, 1.3477, 1.4082, 1.9152, 2.0264, 1.6854, 1.3594, 1.0299, 1.5996,\n",
      "        1.6457, 0.9111, 1.4088, 1.5390, 1.2327, 2.1149, 1.1533, 1.8238, 1.5783,\n",
      "        1.7510, 1.7809])\n",
      "tensor([16.3865, 15.1595, 14.9219, 17.0178, 14.5462, 12.5659, 17.3412, 15.7485,\n",
      "        14.2710, 15.7446, 15.3054, 14.2609, 15.7503, 14.8172, 12.9473, 15.2674,\n",
      "        15.6680, 15.6003, 13.1367, 17.7204])\n",
      "tensor([170.0398, 166.2923, 154.0814, 179.5227])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "input_layer = torch.rand(10) # declaration of input values containing 10 units\n",
    "\n",
    "w1 = torch.rand(10, 20)\n",
    "\n",
    "w2 = torch.rand(20, 20)\n",
    "\n",
    "w3 = torch.rand(20, 4)\n",
    "\n",
    "h1 = torch.matmul(input_layer, w1) # first hidden layer\n",
    "\n",
    "h2 = torch.matmul(h1, w2) # subsequent hidden layer\n",
    "\n",
    "output_layer = torch.matmul(h2, w3) # output layer\n",
    "\n",
    "print(h1)\n",
    "\n",
    "print(h2)\n",
    "\n",
    "print(output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e9676d",
   "metadata": {},
   "source": [
    "### Building a neural network - PyTorch style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9a3e4f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0774,  0.1597,  0.2369, -0.2951], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "## Define a class Net which inherits from nn.Module (look that we are importing torch.nn)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 20)\n",
    "        self.fc2 = nn.Linear(20, 20)\n",
    "        self.output = nn.Linear(20, 4)\n",
    "        \n",
    "# In the __init__ method, we define our parameters, the tensors of weights.\n",
    "# For fully connected layers, they are called nn.Linear.\n",
    "# the first parameter is the number of units of the current layer, while the second parameter is the number of units in the next layer.\n",
    "\n",
    "# In the forward method, we apply all those weights to our input.\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# Finally, we instantiate our model, by calling class Net, and we get the result, by applying object net over our input_layer.\n",
    "input_layer = torch.rand(10)\n",
    "net = Net()\n",
    "result = net(input_layer)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30aa2091",
   "metadata": {},
   "source": [
    "### Creating neural network the hard way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "330af4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([20168.9570, 20113.0781, 20336.9082, 20527.5156, 20118.3789, 19856.6074,\n",
      "        19793.1328, 19242.2520, 20205.8887, 19653.0840])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Your input will be image of size (28, 28), so images containing 784 pixels.\n",
    "input_layer = torch.rand(784)\n",
    "\n",
    "# Initialize the weights of the neural network\n",
    "weight_1 = torch.rand(784, 200) # a hidden layer with 200 units, and an output layer with 10 classes.\n",
    "weight_2 = torch.rand(200, 10)\n",
    "\n",
    "# Multiply input_layer with weight_1\n",
    "hidden_1 = torch.matmul(input_layer, weight_1)\n",
    "\n",
    "# Multiply hidden_1 withh weight_2\n",
    "output_layer = torch.matmul(hidden_1, weight_2)\n",
    "print(output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f55b614",
   "metadata": {},
   "source": [
    "### Creating neural network Object Oriented way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "39ca4ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0557, -0.0043,  0.1090, -0.2566,  0.2374, -0.1103, -0.3727, -0.3776,\n",
      "         0.1971, -0.0331], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 200)\n",
    "        self.fc2 = nn.Linear(200, 10)\n",
    "# Instantiate all 2 linear layers\n",
    "        \n",
    "# Use the instantiated layers and return x\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_layer = torch.rand(784)\n",
    "net = Net()\n",
    "result = net(input_layer)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955b7370",
   "metadata": {},
   "source": [
    "### Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "01cc0145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9696, 0.7527])\n"
     ]
    }
   ],
   "source": [
    "input_layer = torch.tensor([2., 1.])\n",
    "\n",
    "weight_1 = torch.tensor([[0.45, 0.32], [-0.12, 0.29]])\n",
    "\n",
    "hidden_layer = torch.matmul(input_layer, weight_1)\n",
    "\n",
    "weight_2 = torch.tensor([[0.48, -0.12], [0.64, 0.91]])\n",
    "\n",
    "output_layer = torch.matmul(hidden_layer, weight_2)\n",
    "\n",
    "print(output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b176742",
   "metadata": {},
   "source": [
    "### Matrix multiplication is a linear transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a7a61829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9696, 0.7527])\n",
      "tensor([[0.4208, 0.2372],\n",
      "        [0.1280, 0.2783]])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "input_layer = torch.tensor([2., 1.])\n",
    "\n",
    "weight_1 = torch.tensor([[0.45, 0.32], [-0.12, 0.29]])\n",
    "weight_2 = torch.tensor([[0.48, -0.12], [0.64, 0.91]])\n",
    "\n",
    "weight = torch.matmul(weight_1, weight_2)\n",
    "\n",
    "output_layer = torch.matmul(input_layer, weight)\n",
    "\n",
    "print(output_layer)\n",
    "\n",
    "print(weight)\n",
    "\n",
    "# as seen output in the above two cases is exactly similar which concludes:\n",
    "# Network with multiple layers which do not contain non-linearity can be expressed as neural networks with one layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2150539a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 0.])\n",
      "tensor([[2.0000, 0.0000],\n",
      "        [1.2000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "relu = nn.ReLU()\n",
    "\n",
    "tensor_1 = torch.tensor([2., -4.])\n",
    "\n",
    "print(relu(tensor_1))\n",
    "\n",
    "tensor_2 = torch.tensor([[2., -4.],[1.2, 0.]])\n",
    "\n",
    "print(relu(tensor_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9154dce7",
   "metadata": {},
   "source": [
    "### without applying Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "871e99fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2653, 0.1311, 3.8219, 3.0032]])\n",
      "tensor([[0.2653, 0.1311, 3.8219, 3.0032]])\n"
     ]
    }
   ],
   "source": [
    "input_layer = torch.tensor([[ 0.0401, -0.9005, 0.0397, -0.0876]])\n",
    "\n",
    "weight_1 = torch.tensor([[-0.1094, -0.8285, 0.0416, -1.1222],\n",
    "                         [0.3327, -0.0461, 1.4473, -0.8070],\n",
    "                         [0.0681, -0.7058, -1.8017, 0.5857],\n",
    "                         [0.8764, 0.9618, -0.4505, 0.2888]])\n",
    "\n",
    "weight_2 = torch.tensor([[0.6856, -1.7650, 1.6375, -1.5759],\n",
    "                        [-0.1092, -0.1620, 0.1951, -0.1169],\n",
    "                        [-0.5120, 1.1997, 0.8483, -0.2476],\n",
    "                        [-0.3369, 0.5617, -0.6658, 0.2221]])\n",
    "\n",
    "weight_3 = torch.tensor([[0.8824, 0.1268, 1.1951, 1.3061],\n",
    "                        [-0.8753, -0.3277, -0.1454, -0.0167],\n",
    "                        [0.3582, 0.3254, -1.8509, -1.4205],\n",
    "                        [0.3786, 0.5999, -0.5665, -0.3975]])\n",
    "\n",
    "# Calculate the first and second hidden layer\n",
    "hidden_1 = torch.matmul(input_layer, weight_1)\n",
    "hidden_2 = torch.matmul(hidden_1, weight_2)\n",
    "\n",
    "# Calculate the output\n",
    "print(torch.matmul(hidden_2, weight_3))\n",
    "\n",
    "# Calculate weight_composed_1 and weight\n",
    "weight_composed_1 = torch.matmul(weight_1, weight_2)\n",
    "weight = torch.matmul(weight_composed_1, weight_3)\n",
    "\n",
    "# Multiply input_layer with weight\n",
    "print(torch.matmul(input_layer, weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50365e69",
   "metadata": {},
   "source": [
    "### After applying Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f32f9ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2770, -0.0345, -0.1410, -0.0664]])\n",
      "tensor([[-0.2117, -0.4782,  4.0438,  3.0417]])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "relu = nn.ReLU()\n",
    "\n",
    "input_layer = torch.tensor([[ 0.0401, -0.9005, 0.0397, -0.0876]])\n",
    "\n",
    "weight_1 = torch.tensor([[-0.1094, -0.8285, 0.0416, -1.1222],\n",
    "                         [0.3327, -0.0461, 1.4473, -0.8070],\n",
    "                         [0.0681, -0.7058, -1.8017, 0.5857],\n",
    "                         [0.8764, 0.9618, -0.4505, 0.2888]])\n",
    "\n",
    "weight_2 = torch.tensor([[0.6856, -1.7650, 1.6375, -1.5759],\n",
    "                        [-0.1092, -0.1620, 0.1951, -0.1169],\n",
    "                        [-0.5120, 1.1997, 0.8483, -0.2476],\n",
    "                        [-0.3369, 0.5617, -0.6658, 0.2221]])\n",
    "\n",
    "weight_3 = torch.tensor([[0.8824, 0.1268, 1.1951, 1.3061],\n",
    "                        [-0.8753, -0.3277, -0.1454, -0.0167],\n",
    "                        [0.3582, 0.3254, -1.8509, -1.4205],\n",
    "                        [0.3786, 0.5999, -0.5665, -0.3975]])\n",
    "\n",
    "# Apply non-linearity on hidden_1 and hidden_2\n",
    "hidden_1_activated = relu(torch.matmul(input_layer, weight_1))\n",
    "hidden_2_activated = relu(torch.matmul(hidden_1_activated, weight_2))\n",
    "print(torch.matmul(hidden_2_activated, weight_3))\n",
    "\n",
    "# Apply non-linearity in the product of first two weights.\n",
    "weight_composed_1_activated = relu(torch.matmul(weight_1, weight_2))\n",
    "\n",
    "# Multiply weight_composed_1_activated with weight_3\n",
    "weight = torch.matmul(weight_composed_1_activated, weight_3)\n",
    "\n",
    "# Multiply input_layer with weight\n",
    "print(torch.matmul(input_layer, weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53217c73",
   "metadata": {},
   "source": [
    "### Predicted scores are -1.2 for class 0(cat), 0.12 for class 1(car) and 4.8 for class 2(frog). The ground truth is class 2(frog). Compute the loss function in PyTorch. Initialize the tensor of scores with numbers [[-1.2, 0.12, 4.8]], and the tensor of ground truth [2]. Initiate the cross-entropy loss and call it criterion. Compute and print the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6f14bf3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0117)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# Initialize the scores and ground truth\n",
    "logits = torch.tensor([[-1.2, 0.12, 4.8]])\n",
    "ground_truth = torch.tensor([2])\n",
    "\n",
    "# Instantiate cross entropy loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Compute and print the loss\n",
    "loss = criterion(logits, ground_truth)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f49010b",
   "metadata": {},
   "source": [
    "### Loss function of random scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e2150014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.5051)\n"
     ]
    }
   ],
   "source": [
    "# import torch and torch.nn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# initialize logits and ground truth\n",
    "logits = torch.rand(1, 1000)\n",
    "ground_truth = torch.tensor([111])\n",
    "\n",
    "# instantiate cross-entropy loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# calculate and print the loss\n",
    "loss = criterion(logits, ground_truth)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a445a977",
   "metadata": {},
   "source": [
    "## Training a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a65db12",
   "metadata": {},
   "source": [
    "### Preparing Dataset in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5175016e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision # package which deals with datasets and pretrained neural nets\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# define a transformation of images to torch tensors, using transforms.ToTensor() function\n",
    "transform = transforms.Compose(\n",
    "[transforms.ToTensor(),\n",
    "transforms.Normalize((0.4914, 0.48216, 0.44653), (0.24703, 0.24349, 0.26159))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75203e99",
   "metadata": {},
   "source": [
    "### Step1: Datasets and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fcf4ad30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,download=True, transform=transform)\n",
    "\n",
    "# root tells the location of the dataset\n",
    "\n",
    "# set the download flag to True, which tells the PyTorch that if dataset is not in the specified folder, to download and put it there\n",
    "\n",
    "# transforming images to torch tensors by applying the transformation\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "# The first argument of the object is the dataset.\n",
    "\n",
    "# Then we decide the size of the minibatch. Our dataset is too large to be used entirely, instead we decide for each iteration to use only 32 randomly sampled images.\n",
    "\n",
    "# Random part come from shuffle flag.\n",
    "\n",
    "# And finally, we decide how many processes we are going to use to fetch the data in num_workers.\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b048d3f",
   "metadata": {},
   "source": [
    "### inspecting the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "119c4a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 3) (50000, 32, 32, 3)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'trainset_shape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [62], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(testloader\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mshape, trainloader\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Print the computed shapes\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtrainset_shape\u001b[49m, testset_shape)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Compute the size of the minibatch for training set and testing set\u001b[39;00m\n\u001b[0;32m      8\u001b[0m trainset_batchsize \u001b[38;5;241m=\u001b[39m trainloader\u001b[38;5;241m.\u001b[39mbatch_size\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainset_shape' is not defined"
     ]
    }
   ],
   "source": [
    "# Compute the shape of the training set and testing set\n",
    "print(testloader.dataset.data.shape, trainloader.dataset.data.shape)\n",
    "\n",
    "# Print the computed shapes\n",
    "print(trainset_shape, testset_shape)\n",
    "\n",
    "# Compute the size of the minibatch for training set and testing set\n",
    "trainset_batchsize = trainloader.batch_size\n",
    "\n",
    "testset_batchsize = testloader.batch_size\n",
    "\n",
    "# Print sizes of the minibatch\n",
    "print(trainset_batchsize, testset_batchsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8f67f8",
   "metadata": {},
   "source": [
    "### Preparing MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "729a9d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data to torch tensors and normalize it\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307), ((0.3081)))])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# root tells the location of the dataset\n",
    "\n",
    "# set the download flag to True, which tells the PyTorch that if dataset is not in the specified folder, to download and put it there\n",
    "\n",
    "# transforming images to torch tensors by applying the transformation\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=0)\n",
    "\n",
    "# The first argument of the object is the dataset.\n",
    "\n",
    "# Then we decide the size of the minibatch. Our dataset is too large to be used entirely, instead we decide for each iteration to use only 32 randomly sampled images.\n",
    "\n",
    "# Random part comes from shuffle flag."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089d0539",
   "metadata": {},
   "source": [
    "### Inspecting the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4b1dccb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28]) (10000, 32, 32, 3)\n",
      "32 32\n"
     ]
    }
   ],
   "source": [
    "# Compute the shape of the training set and testing set\n",
    "trainset_shape = trainloader.dataset.data.shape\n",
    "testset_shape = testloader.dataset.data.shape\n",
    "\n",
    "# Print the computed shapes\n",
    "print(trainset_shape, testset_shape)\n",
    "\n",
    "# Compute the size of the minibatch for training set and testing set\n",
    "trainset_batchsize = trainloader.batch_size\n",
    "testset_batchsize = testloader.batch_size\n",
    "\n",
    "# Print sizes of the minibatch\n",
    "print(trainset_batchsize, testset_batchsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5059c63",
   "metadata": {},
   "source": [
    "### Step2: Creating a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0c90e8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(32 * 32 * 3, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "# Instantiate all 2 linear layers\n",
    "        \n",
    "# Use the instantiated layers and return x\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c317f6a",
   "metadata": {},
   "source": [
    "### Training the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8fb22f",
   "metadata": {},
   "source": [
    "First we instantiate the net, the loss(cross-entropy) and the optimizer(Adam).\n",
    "We chose the Adam optimizer which works very well, and is a version of gradient descent.\n",
    "Then we loop 10 times over the entire dataset. We use zero_grad() function in order to not accumulate gradients from the previous iterations.\n",
    "When using the iterators, we need to keep track of the number of items in the iterator. This is achieved by an in-built method called enumerate()\n",
    "The forward step is done using net(inputs), giving us the result (in this case output)\n",
    "We compute the loss function in the next line, and then we compute the gradients using loss.backend()\n",
    "Finally, we change the weights using our optimizer with the optimizer.step() command\n",
    "The line inputs = inputs.view(-1, 32 * 32 * 3) simply puts all the entries of the images into vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "213dec9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=3e-4)\n",
    "\n",
    "for epoch in range(10): # loop over the dataset multiple times\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.view(-1, 32 * 32 * 3)\n",
    "        \n",
    "# Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        outputs = net(inputs) # Forward + backward + optimize \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd85f45",
   "metadata": {},
   "source": [
    "### Using the net to get predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613d2af3",
   "metadata": {},
   "source": [
    "we first set the net in test (evaluation) mode using net.eval()\n",
    "The network gives us scores for each class, and\n",
    "we get the class with the highest score (using max function) as prediction.\n",
    "we save the predictions and compute the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a8b3cfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing set accuracy of the network is: 52 %\n"
     ]
    }
   ],
   "source": [
    "correct, total = 0, 0\n",
    "predictions = []\n",
    "net.eval()\n",
    "\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    inputs, labels = data\n",
    "    inputs = inputs.view(-1, 32 * 32 * 3)\n",
    "    \n",
    "    # Do the forward pass and get the predictions\n",
    "    outputs = net(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    predictions.append(outputs)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    \n",
    "print('The testing set accuracy of the network is: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3510f1",
   "metadata": {},
   "source": [
    "## CNN: OOP vs Functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2f533b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "\n",
    "image = torch.rand(16, 3, 32, 32)\n",
    "\n",
    "conv_filter = torch.nn.Conv2d(in_channels=3, out_channels=1, kernel_size=5, stride=1, padding=0)\n",
    "\n",
    "# In torch.nn we need to create a Conv2d filter with these parameters (input channels, output channels, filter size, stride, padding)\n",
    "\n",
    "output_feature = conv_filter = conv_filter(image)\n",
    "print(output_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c87111d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "image = torch.rand(16, 3, 32, 32)\n",
    "\n",
    "filter = torch.rand(1, 3, 5, 5)\n",
    "\n",
    "# in functional, you simply create a random filter\n",
    "\n",
    "out_feat_F = F.conv2d(image, filter, stride=1, padding=0)\n",
    "\n",
    "# to add padding, we just put 1 in the padding parameter.\n",
    "\n",
    "print(out_feat_F.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2ee3a4",
   "metadata": {},
   "source": [
    "### Max Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "56ac3749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[6., 9.],\n",
      "          [3., 4.]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "\n",
    "im = torch.Tensor([[[[3, 1, 3, 5], [6, 0, 7, 9], [3, 2, 1, 4], [0, 2, 4, 3]]]])\n",
    "\n",
    "max_pooling = torch.nn.MaxPool2d(2)\n",
    "\n",
    "output_feature = max_pooling(im)\n",
    "\n",
    "print(output_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "644072f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[6., 9.],\n",
      "          [3., 4.]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "im = torch.Tensor([[[[3, 1, 3, 5], [6, 0, 7, 9], [3, 2, 1, 4], [0, 2, 4, 3]]]])\n",
    "\n",
    "output_feature_F = F.max_pool2d(im, 2)\n",
    "\n",
    "print(output_feature_F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617b8d53",
   "metadata": {},
   "source": [
    "### Average pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4b34b78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[2.5000, 6.0000],\n",
      "          [1.7500, 3.0000]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "\n",
    "im = torch.Tensor([[[[3, 1, 3, 5], [6, 0, 7, 9], [3, 2, 1, 4], [0, 2, 4, 3]]]])\n",
    "\n",
    "max_pooling = torch.nn.AvgPool2d(2)\n",
    "\n",
    "output_feature = max_pooling(im)\n",
    "\n",
    "print(output_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "62ffa6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[2.5000, 6.0000],\n",
      "          [1.7500, 3.0000]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "im = torch.Tensor([[[[3, 1, 3, 5], [6, 0, 7, 9], [3, 2, 1, 4], [0, 2, 4, 3]]]])\n",
    "\n",
    "output_feature_F = F.avg_pool2d(im, 2)\n",
    "\n",
    "print(output_feature_F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019d67a9",
   "metadata": {},
   "source": [
    "## Training Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8eeed8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e0216f",
   "metadata": {},
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9235d8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# define a transformation of images to torch tensors, using transforms.ToTensor() function\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4914, 0.48216, 0.44653), (0.24703, 0.24349, 0.26159))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# root tells the location of the dataset\n",
    "\n",
    "# set the download flag to True, which tells the PyTorch that if dataset is not in the specified folder, to download and put it there\n",
    "\n",
    "# transforming images to torch tensors by applying the transformation\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "# The first argument of the object is the dataset.\n",
    "\n",
    "# Then we decide the size of the minibatch. Our dataset is too large to be used entirely, instead we decide for each iteration to use only 32 randomly sampled images.\n",
    "\n",
    "# Random part comes from shuffle flag.\n",
    "\n",
    "# And finally, we decide how many processes we are going to use to fetch the data in num_workers.\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23b7aa3",
   "metadata": {},
   "source": [
    " ### Building a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1c008710",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc = nn.Linear(128 * 4 * 4, num_classes) # The first dimension of it is the number of units the last layer had (depth) x H x W\n",
    "        # 4 comes from dividing 32 by 2 three times, for each of the pooling we apply after conv filters\n",
    "        \n",
    "    def forward(self, x): # applying parameters to the input\n",
    "        x = self.pool(F.relu(self.conv1(x))) # apply the firs conv filter to the input, following by relu (using functional way) and by the pooling layer\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "            \n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        # prepare the net for the fully connected layer, by squeezing all three dimensions of depth (128), width (4) and height (4) in one dimension,\n",
    "        return self.fc(x) # and then apply the fully connected layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34781a27",
   "metadata": {},
   "source": [
    "### Optimizer and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f1a8845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "net=Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2476392d",
   "metadata": {},
   "source": [
    "### Training a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "64bc8622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10): #loop over all the data in trainloader multiple times\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward + backward + optimize\n",
    "        outputs = net(inputs) #get the data from the loader, and pass it to the net, with the network giving us the predictions\n",
    "        loss = criterion(outputs, labels) # compute the loss function based on the predictions and the labels\n",
    "        loss.backward() # compute the gradients using backward()\n",
    "        optimizer.step() # update the weights using our optimizer\n",
    "        \n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03170a3c",
   "metadata": {},
   "source": [
    "### Evaluating the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0c10bf5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing set accuracy of the network is: 74 %\n"
     ]
    }
   ],
   "source": [
    "correct, total = 0, 0\n",
    "predictions = []\n",
    "net.eval()\n",
    "for i,data in enumerate(testloader, 0):\n",
    "    inputs, labels = data\n",
    "    outputs = net(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    predictions.append(outputs)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    \n",
    "print('The testing set accuracy of the network is: %d %%' % (100 * correct / total))\n",
    "# divide the number of correct predictions by the total number of points in the testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238b552d",
   "metadata": {},
   "source": [
    "## Sequential module - init method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "54c9100d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=5, out_channels=10, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=20, out_channels=40, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(7 * 7 * 40, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 2048)\n",
    "        self.fc3 = nn.Linear(2048, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390167e9",
   "metadata": {},
   "source": [
    "### The sequential module - forward() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4765d98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward():\n",
    "    x = self.relu(self.conv1(x))\n",
    "    x = self.relu(self.pool(self.conv2(x)))\n",
    "    x = self.relu(self.conv3(x))\n",
    "    x = self.relu(self.pool(self.conv4(x)))\n",
    "    x = x.view(-1, 7 * 7 * 40)\n",
    "    x = self.relu(self.fc1(x))\n",
    "    x = self.relu(self.fc2(x))\n",
    "    x = self.fc3(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "141410d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Declare all the layers for feature extraction\n",
    "        self.features = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, padding=1),\n",
    "                                     nn.ReLU(inplace=True),\n",
    "                                     nn.Conv2d(in_channels=5, out_channels=10, kernel_size=3, padding=1),\n",
    "                                     nn.MaxPool2d(2, 2), nn.ReLU(inplace=True),\n",
    "                                     nn.Conv2d(in_channels=10, out_channels=20, kernel_size=3, padding=1),\n",
    "                                     nn.ReLU(inplace=True),\n",
    "                                     nn.Conv2d(in_channels=20, out_channels=40, kernel_size=3, padding=1),\n",
    "                                     nn.MaxPool2d(2, 2), nn.ReLU(inplace=True))\n",
    "        \n",
    "        # Declare all the layers of classification\n",
    "        self.classifier = nn.Sequential(nn.Linear(7 * 7 * 40, 1024), nn.ReLU(inplace=True),\n",
    "                                        nn. Linear(1024, 2048), nn.ReLU(inplace=True),\n",
    "                                        nn.Linear(2048, 10))\n",
    "        \n",
    "        # define all the convolutions, poolings, fully-connected layers etc same as before,\n",
    "        # but now the order of operators matters also in declaration\n",
    "        # Additionally, we encapsulate them within nn.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1315a30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x): # instead of applying each operation, we actually need to apply each sequential module\n",
    "    \n",
    "    # Apply the feature extractor in the input\n",
    "    x = self.features(x) # give the images to the first module which we called features and contains all the convolutional and pooling layers\n",
    "    \n",
    "    # Squeeze the three spatial dimensions in one\n",
    "    x = x.view(-1, 7 * 7 * 40)\n",
    "    \n",
    "    # Classify the images\n",
    "    x = self.classifier(x) # apply the classifier containing three fully connected layers.\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494424c6",
   "metadata": {},
   "source": [
    "## Using validation sets in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8ecad98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision # package which deals with datasets and pretrained neural nets\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "# Shuffle the indices\n",
    "indices = np.arange(60000) #Use numpy.arange() to create an array containing numbers [0, 59999] and then randomly shuffle the array.\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Build the train loader\n",
    "train_loader = torch.utils.data.DataLoader(torchvision.datasets.MNIST(root='./data', download=True, train=True,\n",
    "                     transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])),\n",
    "                     batch_size=64, shuffle=False, sampler=torch.utils.data.SubsetRandomSampler(indices[:55000]))\n",
    "\n",
    "# Build the validation loader\n",
    "val_loader = torch.utils.data.DataLoader(torchvision.datasets.MNIST(root='./data', download=True, train=True,\n",
    "                     transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])),\n",
    "                     batch_size=64, shuffle=False, sampler=torch.utils.data.SubsetRandomSampler(indices[:55000]))\n",
    "\n",
    "# Build the test loader\n",
    "test_loader = torch.utils.data.DataLoader(torchvision.datasets.MNIST(root='./data', download=True, train=False,\n",
    "                     transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])),\n",
    "                     batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8501638e",
   "metadata": {},
   "source": [
    "### Building CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "763edf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Instantiate two convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=5, out_channels=10, kernel_size=3, padding=1)\n",
    "\n",
    "        # Instantiate the ReLU nonlinearity\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Instantiate a fully connected layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Instantiate a fully connected layer\n",
    "        self.fc = nn.Linear(7 * 7 * 10, 10)\n",
    "        \n",
    "# The first dimension of it is the number of units the last layer had (depth) x H x W\n",
    "# 7 comes from dividing 28 by 2 three times, for each of the pooling we apply after conv filters (MNIST images are of size 1x28x28)\n",
    "        \n",
    "    def forward(self, x): # applying parameters to the input\n",
    "        x = self.pool(F.relu(self.conv1(x))) # apply the firs conv filter to the input, following by relu (using functional way) and by the pooling layer\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 7 * 7 * 10)\n",
    "        # prepare the net for the fully connected layer, by squeezing all three dimensions of depth, width and height in one dimension,\n",
    "        return self.fc(x) # and then apply the fully connected layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bd3d3b",
   "metadata": {},
   "source": [
    "### Optimizer & Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "cd686280",
   "metadata": {},
   "outputs": [],
   "source": [
    "net=Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d84cdce",
   "metadata": {},
   "source": [
    "### Training CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1f842a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10): #loop over all the data in trainloader multiple times\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # Get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward + backward + optimize\n",
    "        outputs = net(inputs) #get the data from the loader, and pass it to the net, with the network giving us the predictions\n",
    "        loss = criterion(outputs, labels) # compute the loss function based on the predictions and the labels\n",
    "        loss.backward() # compute the gradients using backward()\n",
    "        optimizer.step() # update the weights using our optimizer\n",
    "        \n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb334048",
   "metadata": {},
   "source": [
    "### Evaluating the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f135d4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing set accuracy of the network is: 98 %\n"
     ]
    }
   ],
   "source": [
    "correct, total = 0, 0\n",
    "predictions = []\n",
    "net.eval()\n",
    "for i,data in enumerate(val_loader, 0):\n",
    "    inputs, labels = data\n",
    "    outputs = net(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    predictions.append(outputs)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    \n",
    "print('The testing set accuracy of the network is: %d %%' % (100 * correct / total))\n",
    "# divide the number of correct predictions by the total number of points in the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "492a6599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing set accuracy of the network is: 98 %\n"
     ]
    }
   ],
   "source": [
    "correct, total = 0, 0\n",
    "predictions = []\n",
    "net.eval()\n",
    "for i,data in enumerate(test_loader, 0):\n",
    "    inputs, labels = data\n",
    "    outputs = net(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    predictions.append(outputs)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    \n",
    "print('The testing set accuracy of the network is: %d %%' % (100 * correct / total))\n",
    "# divide the number of correct predictions by the total number of points in the testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c868e9c4",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f66f8ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        # Define all the parameters of the net\n",
    "        self.calssifier = nn.Sequential(\n",
    "            nn.Linear(28*28, 200),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(200, 500),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(500, 10))\n",
    "\n",
    "# Remember for efficiency to use inplace=True as argument in ReLU() nonlinearity.\n",
    "# Don't forget that the order of operations in sequential module matters.\n",
    "# A fully connected (linear) layer takes as first argument, the number of units in the previous layer, and as second argument, the number of units in the next layer.\n",
    "# As a reminder, the number of classes is 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "50df05bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the forward pass in the forward() method\n",
    "\n",
    "def forward(self, x):\n",
    "    \n",
    "    # Do the forward pass\n",
    "    return self.classifier(x)\n",
    "\n",
    "# The entire network is contained in self.classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81064f94",
   "metadata": {},
   "source": [
    "### Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "647865dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Implement the sequential module for feature extraction\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channel=10, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(2, 2), nn.ReLU(inplace=True), nn.BatchNorm2d(10),\n",
    "            nn.Conv2d(in_channels=10, out_channel=20, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(2, 2), nn.ReLU(inplace=True), nn.BatchNorm2d(20))\n",
    "        \n",
    "        #Implement the fully connected layer for classification\n",
    "        self.fc = nn.Linear(in_features=7*7*20, out_features=10) # we use pooling twice, each time halving the size of the image."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
